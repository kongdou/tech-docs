# 体系结构
MySQL数据库配置文件加载顺序：
- /etc/my.cnf
- /etc/mysql/my.cnf
- /usrlocal/mysql/etc/my.cnf
- ～/.my.cnf

后边覆盖前边

![mysql](https://github.com/kongdou/tech-docs/blob/master/images/Mysql体系结构.png)

## 体系组成
- 连接池组件
- 管理服务和工具组件
- SQL接口组件
- 查询分析器组件
- 优化器组件
- Cache组件
- 插件式存储引擎
- 物理文件

存储引擎是基于**表**的，不是基于数据库的

### InnoDB存储引擎

InnoDB存储引擎支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁。从 MySQL数据库5.5.8版本开始，InnoDB存储引擎是默认的存储引擎。

InmoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL 标准的4种隔离级别，默认为REPEATABLE级别。同时，使用一种被称为next-key-locking的策略来避免幻读（phantom）现象的产生。除此之外，InnoDB储存引擎还提供了插入缓冲（insert buffr）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用的功能。

InnoDB存储引擎采用了聚集（clustered）的方式。

InnoDB是第一个完整支持InnoDB事务的Mysql存储引擎，特点：
- 行级锁
- 支持MVCC
- 支持外键
- 提供一致性非锁定读

#### InnoDB体系结构

![InnoDB](https://github.com/kongdou/tech-docs/blob/master/images/Innodb-arch.png)

后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态。


##### 后台线程：  
InnoDB存储引擎是多线程的模型，因此其后台有多个不同的后台线程，负责处理不同的任务。

(1) Master Thread：  

Master Thread是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插人缓冲（INSERT BUFFER）、UNDO页的回收等。

(2) IO Thread：  
InnoDB存储引擎中大量使用了AIO（异步IO）处理写IO，极大提升了性能，IO Thread的任务是负责这些IO请求的回调(call back)  

**SHOW ENGINES INNODB STATUS**查看InnoDB中的IO Thread  

主要IO线程：
- insert buffer thread
- log thread
- innodb_read_io_threads
- innodb_write_io_thread

(3)Purge Thread  
事务被提交后，其所使用的undo log可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页。在InnoDB 1.1版本之前，purge操作仅在InnoDB存储引擎的Master Thread中完成,1.1后作为单独线程进行，减轻Master Thread的压力

innodb_purge_threads=1(InnoDB 1.1设置只能为1，1.2版本后可以设置多个)

(4) Page Cleaner Thread  
Page Cleaner Thread是在InnoDB1.2.x版本中引入的。其作用是将之前版本中脏页的刷新操作都放入到单独的线程中来完成。而其目的是为了减轻原Master Thread的工作。

##### 内存： 
InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照**页**的方式进行管理。因此可将其视为基于磁盘的数据库系统（Disk-base Database）。

缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将**页"FIX"在缓冲池**中。下一次再读相同的页时，首先判断该页是否在缓冲池中。若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘上的页。
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上。这里需要注意的是，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时，通过CheckPoint的机制刷回磁盘，提高整体性能。

innodb_buffer_pool_size

SHOW VARIABLES LIKE 'innodb_buffer_pool_size'  

![innodb-buffer-pool](https://github.com/kongdou/tech-docs/blob/master/images/innodb-buffer-pool.png)

缓冲池中缓存的数据页类型有：
- 索引页
- 数据页
- undo页
- 插入缓存（insert buffer）
- 自适应哈希索引（adpaptive hash index）
- 锁信息（lock info）
- 数据字典信息(data dictionary)

**可以存在多个缓冲池**，每个页根据哈希值平均分配到不同的缓冲池实例中。

innodb_buffer_pool_instances

InnoDB是怎么对内存区域进行管理？  
数据库中的缓冲池是通过LRU（Lastest Recent Used，最少使用算法来进行管理的），缓冲池中页的默认大小是**16K**，InnoDB存储引擎对LRU做了优化，增加了midpoint位置，避免新访问的页直接放到首部，默认配置到5/8处，  

innodb_old_blocks_pct

在midpoint之前的称为new列表，之后的称为old列表。  

那为什么不采用朴素的LRU算法，直接将读取的页放入到LRU列表的首部呢?这是因为若直接将读取到的页放入到LRU的首部，那么某些SQL操作可能会使缓冲池中的页被刷新出，从而影响缓冲池的效率。常见的这类操作为索引或数据的扫描操作。这类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操作中需要，并不是活跃的热点数据。如果页被放入LRU列表的首部，那么非常可能将所需要的热点数据页从LRU列表中移除，而在下一次需要读取该页时，InnoDB存储引擎需要再次访问磁盘。

为了解决这个问题，innodb存储引擎引入了innodb_old_blocks_time, 用于表示页读取到mid位置后需要等待多久才会被加入到LRU列表的热数据区

innodb_old_blocks_time=1000，毫秒，表示将数据放到冷热交接处，过了1S仍然存活，放到热数据区


LRU列表用来管理已经读取的页，但当数据库刚启动时，LRU列表是空的，即没有任何的页。这时页都存放在Fre列表中。当需要从缓冲池中分页时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。当页从LRU列表的old部分加入到new部分时，称此时发生的操作为page made young，而因为inodb oldblocks_time的设置而导致页没有从old部分移动到new部分的操作称为page not made young。可以通过命令SHOW ENGINE INNODB STATUS来观察LRU列（LRU如果页不够，先从Free列表中看是否有空闲的页，如果没有进行淘汰）

**SHOW ENGINE INNODB STATUS** 查看

InnoDB存储引擎从1.0.x版本开始支持压缩页的功能，即将原本16KB的页压缩为IKB、2KB、4KB和8KB。而由于页的大小发生了变化，LRU列表也有了些许的改变。对于非16KB的页，是通过 unzipLRU列表进行管理的。通过命令SHOW ENGINE INNODB STATUS 可以观察到如下内容∶

![unzip-lru](https://github.com/kongdou/tech-docs/blob/master/images/unzip-lru.png)

如图所示：LRU中有1539个页，而unzip_LRU有156个（注：LRU个数已包含unzip_LRU）

对于压缩页的表，每个表的压缩比率可能各不相同。可能存在有的表页大小为8KB，有的表页大小为2KB的情况。unzipLRU是怎样从缓冲池中分配内存的呢?  
首先，在unzip_LRU列表中对不同压缩页大小的页进行分别管理。其次，通过伙伴算法进行内存的分配。例如对需要从缓冲池中申请页为4KB的大小，其过程如下∶  
    1）检查4KB的unzip_LRU列表，检查是否有可用的空闲页;  
    2）若有，则直接使用∶   
    3）否则，检查8KB的 unzipLRU列表∶  
    4）若能够得到空闲页，将页分成2个4KB页，存放到4KB的unzipLRU列表;5）若不能得到空闲页，从LRU列表中申请一个16KB的页，将页分为1个8KB的页、2个 4KB的页，分别存放到对应的unzipLRU列表中。  


脏页：  
在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过CHECKPOINT机制将脏页刷新回磁盘，而Flush列表中的页即为脏页列表。需要注意的是，脏页既存在于LRU列表中，也存在于Flsh列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。


重做日志缓冲（Redo log buffer）  
InnoDB存储引擎首先将重做日志信息放入到缓冲区，然后按照一定的频率将其刷新到重做日志文件中。
重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。该值可由配置参数 inodb_logbuffrsize控制，默认为8MB:

触发重做日志内容到外部磁盘的条件：
- Master Thread 每一秒将重做日志缓冲刷新到重做日志文件
- 每个事务提交时，将重做日志缓冲刷到日志文件
- 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件

CheckPoint技术：  

前面已经讲到了，缓冲池的设计目的为了协调CPU速度与磁盘速度的鸿沟。因此页的操作首先都是在缓冲池中完成的。如果一条DML语句，如Update或Delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新。数据库需要将新版本的页从缓冲池刷新到磁盘。

如果每一次缓冲池中页的变化，就将新页的版本刷新到磁盘，这个开销非常大，如果在缓冲池中将页的新版本刷新到磁盘时宕机，数据将不能修复，为了避免数据丢失，当前事务数据库普遍采用的write Ahead log策略，即当前事务提交时，先写重做日志，再修改页。

checkpoint技术的目的解决以下几个问题：
1. 缩短数据库的恢复时间
2. 缓冲池不够用时，将脏数据刷回磁盘
3. 重做日志不可用时，刷新脏页？？

checkpoint类型：
- Sharp CheckPoint
- Fuzzy CheckPoint

Sharp CheckPoint：  
发生在数据库关闭时将所有的脏页都刷回磁盘，这是默认的工作方式，

这里笔者进行了概括，在InnoDB存储引擎中可能发生如下几种情况的Fuzzy Checkpoint:
- Master Thread Checkpoint（异步将一定比例的脏页刷回到磁盘）
- FLUSH_LRU_LIST Checkpoint
- Async/Sync Flush Checkpoin
- Dirty Page too much Checkpoint

FLUSHLRU_LISTCheckpoint是因为InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。在InoDB1.1x版本之前，需要检查LRU列表中是否有足够的可用空间操作发生在用户查询线程中，显然这会阻塞用户的查询操作。倘若没有100个可用空闲页，那么InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页中有脏页，那么需要进行Checkpoint，而这些页是来自LRU列表的，因此称为FLUSH_LRU_LIST Checkpoint。

而从MySQL5.6版本，也就是InnoDB1.2.x版本开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数inodb Iru_scan_depth控制LRU列表中可用页的数量，该值默认为1024，如∶

Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。在nnoDB 1.2.x版本之前，Async Flush Checkpoint会阻塞发现问题的用户查询线程，而Sync Flush Checkpoint 会阻塞所有的用户查询线程，并且等待脏页刷新完成。从InnoDB 1.2.x版本开始———也就是MySQL5.6版本，这部分的刷新操作同样放入到了单独的Page Cleaner Thread中，故不会阻塞用户查询线程。

Dirty Page too much，即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可用的页。其可由参数 innodb_max_dirty_pages_pct控制∶

innodb_max_dirty_pages_pct

innodb_max_dirtypagespct值为75表示，当缓冲池中脏页的数量占据75%时，强制进行 Checkpoint，刷新一部分的脏页到磁盘。在InnoDB 1.0.x版本之前，该参数默认值为90，之后的版本都为75。

InnoDB1.0之前的Master Thread：  
Master Thread具有最高的线程级别，内部有多个循环（loop）组成:
- 主循环（loop）
- 后台循环（backgroup loop）
- 刷新循环（flush loop）
- 暂停循环（suspend loop）

Master Thread会根据数据库的运行状态在以上几个循环之间切换  

主循环每秒一次或者每10秒一次的操作是不准确的，在负载大的情况下可能就有延迟，每秒一次的操作包括：
- 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）;
- 合并插人缓冲（可能）;
- 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）;
- 如果当前没有用户活动，则切换到 background loop（可能）

即使某个事务还没有提交，InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件。这一点是必须要知道的，因为这可以很好地解释为什么再大的事务提交（commit）的时间也是很短的。

合并插入缓冲（Insert Buffer）并不是每秒都会发生的。InoDB存储引擎会判断当前一秒内发生的IO次数是否小于5次，如果小于**5次**，InnoDB认为当前的IO压力很小，可以执行合并插人缓冲的操作。  

刷新100个脏页也不是每秒都会发生的。InoDB存储引擎通过判断当前缓冲池中脏页的比例（buf_get_modified_ratio_pct）是否超过了配置文件中inodb_max_dirty_pages_pct这个参数（默认为90，代表90%），如果超过了这个阈值，InnoDB存储引擎认为需要做磁盘同步的操作，将100个脏页写人磁盘中。


//缺少待补充


### InnoDB关键特征
- 插入缓存
- 两次写
- 自适应哈希索引
- 异步IO
- 刷新邻接页

插入缓存：  
Insert Buffer和数据页一样，也是物理页的一个组成部分。
在InnoDB存储引擎中，主键是行唯一的标识符。通常应用程序中行记录的插人顺序是按照主键递增的顺序进行插入的。因此，插入聚集索引（Primary Key）一般是顺序的，不需要磁盘的随机读取。

不可能每一张表上都只有一个聚集索引，更多情况是一张表上有多个非聚集的辅助索引（secondry index）。在这样的情况下产生了一个非聚集的且不是唯一的索引，非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降。

InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插人或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插人;若不在，则先放入到一个Insert Buffer对象中，好似欺骗。数据库这个非聚集的索引已经插到叶子节点，而实际并没有，只是存放在另一个位置。然后再以一定的频率和情况进行 Insert Buffer和辅助索引页子节点的merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能。

然而Insert Buffer的使用需要同时满足以下两个条件：
- 索引是辅助索引
- 索引不是唯一的


两次写：  
如果说Insert Buffer带给InnoDB存储引擎的是性能上的提升，那么doublewrite（两次写）带给 InnoDB存储引擎的是数据页的可靠性。

Double Write解决的问题：  
一个数据页的大小是16K，假设在把内存中的脏页写到数据库的时候，写了2K突然掉电，也就是说前2K数据是新的，后14K是旧的，那么磁盘数据库这个数据页就是不完整的，是一个坏掉的数据页。redo只能加上旧、校检完整的数据页恢复一个脏块，不能修复坏掉的数据页，所以这个数据就丢失了，可能会造成数据不一致，所以需要double write。

使用情景：  
当数据库正在从内存向磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为**重做日志记录的是对页的物理修改**，如果页本身已经损坏，重做日志也无能为力。

![doube-write](https://github.com/kongdou/tech-docs/blob/master/images/doube-write.png)


doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。  

1、当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中；  

2、接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；  

待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖)

4、doublewrite的崩溃恢复，如果操作系统在将页写入磁盘的过程中发生崩溃，在恢复过程中，innodb存储引擎可以从共享表空间的doublewrite中找到该页的一个最近的副本，将其复制到表空间文件，再应用redo log，就完成了恢复过程。  


异步IO：  
为了提高磁盘操作性能，当前的数据库系统都采用异步IO。  
与AIO对应的是SyncIO，即每进行一次IO操作，需要等待此次操作结束才能继续接下来的操作。但是如果用户发出的是一条索引扫描的查询，那么这条SQL查询语句可能需要扫描多个索引页，也就是需要进行多次的IO操作。在每扫描一个页并等待其他完成后再进行下一次的扫描。  

AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并成1个IO。  

InnoDB1.1.x开始，支持内核级别的AIO支撑，称为Native AIO，Native AIO需要操作系统提供支持

innodb_use_native_aio

刷新邻接页：  
工作原理为：当刷新一个脏页时，InoDB存储引擎会检测该页所在区（extent）的所有页，如果是脏页，那么一起进行刷新。这样做的好处显而易见，通过AIO可以将多个IO写人操作合并为一个IO操作，故该工作机制在**传统机械磁盘**下有着显著的优势。

问题：
- 是不是可能将不怎么脏的页进行了写人，而该页之后又会很快变成脏页?
- 固态硬盘有着较高的IOPS，是否还需要这个特性?

开关：innodb_flush_neighbors，是否启用该特征

启动、关闭和恢复：  
innodb_fast_shutdown，值可以设置为0、1、2

0表示在MySQL数据库关闭时，InnoDB需要完成所有的full purge和merge insert buffer，并且将所有的脏页刷新回磁盘。这需要一些时间，有时甚至需要几个小时来完成。如果在进行InnoDB升级时，必须将这个参数调为0，然后再关闭数据库。

1是参数innodb_fastshutdown的默认值，表示不需要完成上述的full purge和merge insert buffr操作，但是在缓冲池中的一些数据脏页还是会刷新回磁盘。

2表示不完成full purge和merge insert buffer操作，也不将缓冲池中的数据脏页写回磁盘，而是将日志都写人日志文件。这样不会有任何事务的丢失，但是下次MySQL数据库启动时，会进行恢复操作（recovery）





## 索引与算法

InnoDB存储引擎支持以下几种常见的索引：
- B+树索引
- 全文索引
- 哈希索引

InnoDB存储引擎支持的哈希索引是自适应的，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。

B+树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。B+树索引并不能找到一个给定键值的具体行。

B+树索引能找到的只是被查找数据行所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。

二分查找法：  
二分查找法（binary search）也称为折半查找法，用来查找一组有序的记录数组中的某一记录，其基本思想是∶将记录按有序化（递增或递减）排列，在查找过程中采用跳跃式方式查找，即先以有序数列的中点位置为比较对象，如果要找的元素值小于该中点元素，则将待查序列缩小为左半部分，否则为右半部分。通过一次比较，将查找区间缩小一半。  

二叉查找树和平衡二叉树：  
B+树是通过二叉查找树，再由平衡二叉树，B树演化而来。

平衡二叉树：  
任何节点的两个子树的最大高度差为1

B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在B+树中，所有记录节点都是按键值的大小顺序存放在**同一层的叶子节点**上，由各叶子节点指针进行连接。B+树索引是双向链表

数据库中的B+树索引可以分为聚集索引（clustered inex）和辅助索引（secondary index）e，但是不管是聚集还是辅助的索引，其内部都是B+树的，即高度平衡的，叶子节点存放着所有的数据。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息。

聚集索引：  
InnoDB存储引擎表是索引组织表，即表中数据是按照主键顺序存放，而聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。

聚集索引的存储并不是物理上连续的，而是逻辑上连续的  

辅助索引：  
辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含**键值**以外，每个叶子节点中的索引行中还包含了一个**书签**（bookmark）。该书签用来告诉InnoDB存储引擎哪里**可以找到与索引相对应的行数据**。由于InnoDB存储引擎表是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。


先通过辅助索引

辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InoDB存储引擎会遍历辅助索引并通过**叶级别的指针**获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。


Cardinality值非常关键，表示索引中不重复记录数量的预估值。Cardinality是一个预估值，而不是一个准确值，基本上用户也不可能得到一个准确的值。

在实际应用中，Cardinality/n_rows in table应尽可能地接近1。如果非常小，那么用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对这个字段添加 B+树索引是非常有必要的。

数据库对于Cardinality的统计都是通过采样（Sample）的方法来完成的。在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中∶INSERT和UPDATE。根据前面的叙述，不可能在每次发生 INSERT和UPDATE时就去更新Cardinality信息，这样会增加数据库系统的负荷，同时对于大表的统计，时间上也不允许数据库这样去操作。因此，InnoDB存储引擎内部对更新Cardinality信息的策略为∶
- 表中1/16的数据已发生过变化 
- stat modified_counter>2 000 000 000

第一种策略为自从上次统计Cardinality信息后，表中1/16的数据已经发生过变化，这时需要更新Cardinality信息。第二种情况考虑的是，如果对表中某一行数据频繁地进行更新操作，这时表中的数据实际并没有增加，实际发生变化的还是这一行数据，则第一种更新策略就无法适用这这种情况。故在InnoDB存储引擎内部有一个计数器stat_modifed counter，用来表示发生变化的次数，当stat modified couter大于200000 000时，则同样需要更新 Cardinality信息。



如何进行Cardinality信息的统计：
 - 取得B+树索引中叶子节点的数量，记为A。
- 随机取得B+树索引中的8个叶子节点。统计每个页不同记录的个数，即为P1，P2，...，P8
- 根据采样信息给出 Cardinality的预估值∶Cardinality=（P1+P2+…·+P8）*A/8

通过上述的说明可以发现，在InnoDB存储引擎中，Cardinality值是通过对8个叶子节点预估而得的，不是一个实际精确的值。再者，每次对Cardinality值的统计，都是通过随机取8个叶子节点得到的，这同时又暗示了另一个Cardinality现象，即每次得到的Cardinality值可能是不同的。


覆盖索引：
InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。

InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。

从InnoDB1.2.x版本开始，InnoDB存储引擎开始支持全文检索，其支持MyISAM 存储引擎的全部功能，并且还支持其他的一些特性



## 锁
InnoDB存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。

lock与latch：  
latch一般称为门锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在InnoDB存储引擎中，latch又可以分为mutex（互斥量）和rwlock（读写锁）。其目的是用来保证并发线程操作临界资源的正确性，并且通常**没有死锁检测的机制**。

lock的对象是事务，用来锁定的是数据库中的对象，如**表、页、行**。并且一般lock 的对象仅在事务commit 或rollback后进行释放（不同事务隔离级别释放的时间可能不同）。此外，lock，正如在大多数数据库中一样，是**有死锁机制**的。表6-1显示了lock与latch 的不同。


InnoDB存储引擎实现了如下两种标准的行级锁∶
- 共享锁（S Lock），允许事务读一行数据。
- 排他锁（XLock），允许事务删除或更新一行数据。

X锁与任何锁都不兼容，S锁仅和S锁兼容

InnoDB存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为**意向锁**（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在**更细粒度（fine granularity）上进行加锁**。

InnoDB存储引擎支持意向锁设计比较简练，其意向锁即为表级别的锁。

1）意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
2）意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁

一致性非锁定读：

一致性的非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。

读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。

非锁定读机制极大地提高了数据库的并发性。在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同。

一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control,MVCC)。

在事务隔离级别READ COMMITTED和REPEATABLE READ（InnoDB存储引擎的默认事务隔离级别）下，InoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。  

在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的**最新一份快照数据**  
在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取**事务开始时的行数据版本**  

一致性锁定读：  

显式地对数据库读取操作进行加锁以保证数据逻辑的一致性
- SELECT…FOR UPDATE
- SELECT…LOCK IN SHARE MODE

SELECT·…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。
SELECT…LOCKIN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加 X锁，则会被阻塞。

外键主要用于引用完整性的约束检查。在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎自动对其加一个索引，因为这样可以避免表锁。  

对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT父表。但是对于父表的SELECT操作，不是使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这时使用的是SELECT.·…LOCK IN SHARE MODE方式，即主动对父表加一个S锁。如果这时父表上已经这样加X锁，子表上的操作会被阻塞。


锁的算法：
- Record Lock：单个行记录上的锁
- Gap Lock：间隙锁，锁定的是一个范围，但不包括记录本身
- Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身

Phantom Problem是指在同一事务下，连续执行两次同样的SQL 语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

脏数据却截然不同，脏数据是指未提交的数据，如果读到了脏数据，即一个事务可以读到另外一个事务中未提交的数据，则显然违反了数据库的隔离性。

在一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读  

不可重复读和脏读的区别是∶脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。（事务隔离级别为READ COMMITTED，不可重复读问题是可以接受的，因为数据是提交后的数据）

InnoDB存储事务隔离级别是READ REPEATABLE，采用Next-Key Lock（锁定范围）算法，避免了不可重复读的现象。


死锁：  
死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。

解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。

innodb_lock_wait_timeout 

当前数据库还都普遍采用**wait-for graph（等待图）**的方式来进行死锁检测  

wait-for graph（等待图）要求数据库保存以下信息：  
1. 锁的信息链表
2. 事务等待链表

wait-for graph是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。

锁升级：

锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，数据库可以把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁。如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象。

- 由**一句单独的SQL语句**在**一个对象上**持有的**锁的数量超过了阈值**，默认这个阈值为5000。值得注意的是，如果是不同对象，则不会发生锁升级
- 锁资源占用的内存超过了激活内存的40%时就会发生锁升级

InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的**每个页**对锁进行管理的，采用的是位图(30字节)的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。  

假设一张表有30000个数据页，每个页大约有100条记录，那么总共有3000000 条记录。若有一个事务执行全表更新的SQL语句，则需要对所有记录加X锁。若根据每行记录产生锁对象进行加锁，并且每个锁占用10字节，则仅对锁管理就需要差不多需要3GB的内存。而InnoDB存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用30个字节，则锁对象仅需90MB的内存。由此可见两者对于锁资源开销的差距之大。

## 事务
重做日志用来实现事务的持久性（D），两部分组成：
- 内存中的redo log buffer,易失性
- 重做日志文件 redo log file，持久性

InnoDB存储引擎中，由两部分组成，即 **redo log**和**undo log**。

redo log用来保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。

redo log基本上都是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作。而undo log是需要进行随机读写的。


由于重做日志文件打开并没有使用O_DIRECT选项，因此重做日志缓冲先写入文件系统缓存。为了确保重做日志写入磁盘，必须进行一次 fsync操作。由于fsync的效率取决于磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据库的性能。

binlog（二进制日志）：  
用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立，binlog与redo的区别：  
- redo日志是在InnoDB存储引擎层产生，而二进制日志是在Mysql数据库的上层产生
- 内容不同，binlog是一种逻辑日志，记录的是对应的sql；而redo日志是物理格式日志，**记录对每个页的修改**
- 写入磁盘的时间点也不同，二进制日志是在事务提交后进行一次写入，而InnoDB存储引擎的重做日志在事务进行过程中不断地被写入

在InnoDB中，重做日志都是以512字节进行存储，这意味着重做日志缓存、重做日志文件都是以**块（block）**的方式进行保存的，称之为**重做日志块（redo log block）**，每块的大小为**512**字节。

若一个页中产生的重做日志数量大于512字节，那么需要**分割**为多个重做日志块进行存储。此外，由于重做日志块的大小和磁盘扇区大小一样，都是512字节，因此重做日志的写入可以保证原子性，不需要double write技术

重做日志块的结构由三部分组成：
- 日志块头（log block header）,占用12个字节
- 日志块尾（log block tailer）,占用8个字节
- 日志内容（log body）,占用492个字节

所以每个日志块最多能够存储日志的大小492字节（512-12-8）

![redo-log-buffer](https://github.com/kongdou/tech-docs/blob/master/images/redo-log-buffer.png)

log block header由4部分组成：
- LOG







































 



## 其他内容
### MyISAM存储引擎

MyISAM存储引擎不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用。

MyISAM存储引擎表由 MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。

SHOW ENGINES

### NDB
NDB存储引擎是一个集群存储引擎，类似于Oracle的RAC集群，不过与Qracle RAC share everything架构不同的是，其结构是share nothing的集群架构，因此能提供更高的可用性。

NDB的特点是数据全部放在内存中。

### Memory存储引擎
Memory存储引擎（之前称HEAP存储引擎）将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失。它非常适合用于存储临时数据的临时表，以及数据仓库中的纬度表。Memory存储引擎默认使用**哈希索引**，而不是我们熟悉的**B+树**索引。

限制：
- 表锁，并发性差
- 不支持BLOB、TEXT列类型
- 存储变长字段时是按照定常字段方式存储，浪费存储空间

### Archive 存储引擎
Archive存储引擎只支持INSERT和SELECT操作，从MySQL5.1开始支持索引。Archive存储引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比一般可达1∶10。

使用行锁实现高并发，但是不是事务安全的存储引擎，主要是提供高速插入和压缩功能

### 连接Mysql
连接MySQL操作是一个连接进程和MySQL数据库实例进行通信。

1. TCP/IP

TCP/IP套接字方式是MySQL数据库在任何平台下都提供的连接方式，也是网络中使用得最多的一种方式。这种方式在TCPIP连接上建立一个基于网络的连接请求。
mysql -h xxx.xxx.xxx.xxx -u xxx -p

这里需要注意的是，在通过TCP/IP连接到MySQL实例时，MySQL数据库会先检查一张**权限视图**，用来判断发起请求的客户端IP是否允许连接到MySQL实例。该视图在mysql架构下，表名为user

2. UNIX

在Linux和UNIX环境下，还可以使用UNIX域套接字。UNIX域套接字其实不是一个网络协议，所以只能在MySQL客户端和数据库实例在一台服务器上的情况下使用。










